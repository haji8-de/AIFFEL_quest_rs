{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/haji8-de/AIFFEL_quest_rs/blob/main/Exploration/Ex03/ablation_study_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PU4ol_fiKTOD",
    "outputId": "77bcd990-39e7-461a-8aa2-bb861d3674c7"
   },
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hyrckZzxIQD"
   },
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchinfo import summary\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaqfEttqHbnO",
    "outputId": "38c44ff9-289f-4132-f1ff-dbc09351391e"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrLTrV6KImlO"
   },
   "outputs": [],
   "source": [
    "# Q. 이미지의 표현이 0과 1 사이로 들어오도록 직접 Pytorch 정규화 코드를 작성해봅시다.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # uint8 → float32 변환 + 0~1 정규화\n",
    "    # 이미지 픽셀 값을 255로 나누어 0과 1 사이로 정규화하기 위해 transforms.ToTensor()를 사용한다.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeE3xIbtJMMM"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    return np.transpose(npimg, (1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyOFxhzqKTOV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "hyperparams = {\n",
    "    \"batch_size\": 4,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 5,\n",
    "    \"transform\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.48235, 0.45882, 0.40784],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KrWgUf69OM9E",
    "outputId": "d9f49be4-f5ac-460b-e47c-8e61576cc8f2"
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.OxfordIIITPet(root='./data', split='trainval', download=True, target_types=[\"binary-category\",\"category\"], transform=hyperparams['transform'])\n",
    "testset = torchvision.datasets.OxfordIIITPet(root='./data', split='test', download=True, target_types=[\"binary-category\",\"category\"], transform=hyperparams['transform'])\n",
    "\n",
    "trainloader_2 = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader_2 = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# trainloader_2 = torch.utils.data.DataLoader(ds_split['train'], batch_size=32, shuffle=True)\n",
    "# testloader_2 = torch.utils.data.DataLoader(ds_split['test'], batch_size=32, shuffle=False)\n",
    "# validationloader_2 = torch.utils.data.DataLoader(ds_split['validation'], batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67d5ed55"
   },
   "outputs": [],
   "source": [
    "def show_multiple_images_binary_label(dataset, n_images=9):\n",
    "    dataiter = iter(dataset)\n",
    "    images, labels = next(dataiter)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # OxfordIIITPet 데이터셋의 이진 레이블에 대한 이름을 정의합니다.\n",
    "    # 'binary-category'는 일반적으로 0:cat, 1:dog을 나타냅니다.\n",
    "    binary_labels_map = ['cat', 'dog']\n",
    "\n",
    "    for i in range(n_images):\n",
    "        ax = axes[i]\n",
    "        img = imshow(images[i])\n",
    "        ax.imshow(img)\n",
    "\n",
    "        # labels는 (binary_labels_batch_tensor, category_labels_batch_tensor) 형태이므로\n",
    "        # 첫 번째 텐서(binary_labels_batch_tensor)에서 i번째 항목을 가져옵니다.\n",
    "        binary_label_idx = labels[0][i].item()\n",
    "\n",
    "        # 인덱스가 유효한 범위 내에 있는지 확인하고, 아니면 'Unknown'으로 처리합니다.\n",
    "        if 0 <= binary_label_idx < len(binary_labels_map):\n",
    "            label_text = binary_labels_map[binary_label_idx]\n",
    "        else:\n",
    "            label_text = f\"Unknown (Index: {binary_label_idx})\"\n",
    "\n",
    "        ax.set_title(f\"Label: {label_text}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b9ff5395",
    "outputId": "0b3e5d47-df80-4954-cc17-c6e9967f69a6"
   },
   "outputs": [],
   "source": [
    "# trainloader_2 에 대한 이진 레이블 시각화\n",
    "print(\"Trainloader_2 (Binary Labels):\")\n",
    "show_multiple_images_binary_label(trainloader_2)\n",
    "\n",
    "# testloader_2 에 대한 이진 레이블 시각화\n",
    "print(\"\\nTestloader_2 (Binary Labels):\")\n",
    "show_multiple_images_binary_label(testloader_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dynO2yoHKGZd"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes, planes,\n",
    "            kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes,\n",
    "            kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inplanes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    inplanes, self.expansion*planes,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-WZ6jbSKTOY"
   },
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes, planes,\n",
    "            kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes,\n",
    "            kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            planes, self.expansion*planes,\n",
    "            kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inplanes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    inplanes, self.expansion*planes,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocWtDQzAKI7Y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.inplanes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.stage1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.stage2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.stage3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.stage4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(num_blocks - 1):\n",
    "            layers.append(block(self.inplanes, planes, 1))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.stage1(out)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwI1e8N2KTOc",
    "outputId": "53c07c56-28f1-45b5-83e4-4f707d8d1163"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "resnet18 = ResNet(BasicBlock, [2, 2, 2, 2], 1000)\n",
    "resnet34 = ResNet(BasicBlock, [3, 4, 6, 3], 1000)\n",
    "resnet50 = ResNet(BottleneckBlock, [3, 4, 6, 3], 1000)\n",
    "resnet101 = ResNet(BottleneckBlock, [3, 4, 23, 3], 1000)\n",
    "resnet152 = ResNet(BottleneckBlock, [3, 8, 36, 3], 1000)\n",
    "torch_model = models.resnet34(weights=\"ResNet34_Weights.IMAGENET1K_V1\")\n",
    "\n",
    "resnet34_info = summary(resnet34, (1, 3, 224, 224), verbose=0)\n",
    "torch_model_info = summary(torch_model, (1, 3, 224, 224), verbose=0)\n",
    "\n",
    "print(resnet34_info.total_params)\n",
    "print(torch_model_info.total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94SouF30mruJ",
    "outputId": "955efcab-380e-43fa-f116-3c48f9cd360d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSHJD6YSg9LS"
   },
   "outputs": [],
   "source": [
    "\n",
    "class build_resnet():\n",
    "  def __init__(self, is_50, input_shape=(32,32,3), num_classes=1000):\n",
    "    self._is_50 = is_50 # Store the parameter as an instance attribute\n",
    "    self._input_shape = input_shape # Store input_shape for potential future use\n",
    "    self._num_classes = num_classes # Store num_classes\n",
    "\n",
    "    if self._is_50: # Use the instance attribute to determine the model type\n",
    "      self.model = ResNet(BottleneckBlock, [3, 4, 6, 3], self._num_classes)\n",
    "      self.block_type = BottleneckBlock\n",
    "    else:\n",
    "      self.model = ResNet(BasicBlock, [3, 4, 6, 3], self._num_classes)\n",
    "      self.block_type = BasicBlock\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "\n",
    "  def summary(self):\n",
    "    # Use standard input size for ResNet summary, e.g., for ImageNet\n",
    "    return summary(self.model, (1, 3, 224, 224), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Go9QB0zp6RR",
    "outputId": "f4bf8eef-a3a6-4435-f2ea-c911df78a14c"
   },
   "outputs": [],
   "source": [
    "# @title ResNet34 Summary\n",
    "resnet_34_2 = build_resnet(is_50=False, input_shape=(32, 32,3), num_classes=2)\n",
    "print(resnet_34_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lhkr4SZyKTOe",
    "outputId": "425c5e44-2954-4775-f183-720e13471447"
   },
   "outputs": [],
   "source": [
    "# @title ResNet50 Summary\n",
    "resnet_50_2 = build_resnet(is_50=True, input_shape=(32, 32,3), num_classes=2)\n",
    "print(resnet_50_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsAjcaFVKTOj"
   },
   "outputs": [],
   "source": [
    "# @title model 설정 : ResNet50\n",
    "model = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J65h_7NhKTOj"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=hyperparams[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "Y5RRShz975_T",
    "outputId": "db7c7893-7a5a-4ca0-eb1c-3fd8b4bbf3cc"
   },
   "outputs": [],
   "source": [
    "\n",
    "for images, classes in trainloader_2:\n",
    "    images = images.to(device)\n",
    "    classes = classes[0][1]#.item()\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Free up memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBUvN2hGKTOk"
   },
   "outputs": [],
   "source": [
    "for epoch in range(hyperparams[\"epochs\"]):\n",
    "    cost = 0.0\n",
    "\n",
    "    for images, classes in trainloader_2:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # --- THE FIX ---\n",
    "        # classes is a list: [binary_targets, category_targets]\n",
    "        # 1. Select the second tensor (Index 1 is \"category\")\n",
    "        target_labels = classes[1] \n",
    "        \n",
    "        # 2. Move ONLY that tensor to the device\n",
    "        target_labels = target_labels.to(device)\n",
    "        # ---------------\n",
    "\n",
    "        output = model(images)\n",
    "        \n",
    "        # Ensure target is the correct shape/type for loss (usually Long)\n",
    "        # If your output is shape [32, 10], target_labels should be [32]\n",
    "        loss = criterion(output, target_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss.item() # .item() converts it to a simple float, freeing the GPU memory\n",
    "\n",
    "    cost = cost / len(trainloader_2)\n",
    "    print(f\"Epoch : {epoch+1:4d}, Cost : {cost:.3f}, Loss : {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UhUHI3H9fyZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    accuracy = 0.0\n",
    "    for images, classes in testloader_2:\n",
    "        images = images.to(device)\n",
    "        classes = classes[1].to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=-1)\n",
    "        outputs_classes = torch.argmax(probs, dim=-1)\n",
    "\n",
    "        accuracy += int(torch.eq(classes, outputs_classes).sum())\n",
    "\n",
    "    print(f\"acc@1 : {accuracy / (len(testloader) * hyperparams['batch_size']) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7g9uNPp9qkJ"
   },
   "outputs": [],
   "source": [
    "def show_multiple_images_binary_label(dataset, n_images=9):\n",
    "    dataiter = iter(dataset)\n",
    "    images, labels = next(dataiter)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # OxfordIIITPet 데이터셋의 이진 레이블에 대한 이름을 정의합니다.\n",
    "\n",
    "    for i in range(n_images):\n",
    "        ax = axes[i]\n",
    "        img = imshow(images[i])\n",
    "        ax.imshow(img)\n",
    "\n",
    "        # labels는 (binary_labels_batch_tensor, category_labels_batch_tensor) 형태이므로\n",
    "        # 첫 번째 텐서(binary_labels_batch_tensor)에서 i번째 항목을 가져옵니다.\n",
    "\n",
    "\n",
    "        # 인덱스가 유효한 범위 내에 있는지 확인하고, 아니면 'Unknown'으로 처리합니다.\n",
    "        if 0 <= binary_label_idx < len(binary_labels_map):\n",
    "            label_text = binary_labels_map[binary_label_idx]\n",
    "        else:\n",
    "            label_text = f\"Unknown (Index: {binary_label_idx})\"\n",
    "\n",
    "        ax.set_title(f\"Label: {label_text}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 'binary-category'는 일반적으로 0:cat, 1:dog을 나타냅니다.\n",
    "binary_labels_map = ['cat', 'dog']\n",
    "def display_predictions_binary_label(loader, model, class_names, device, n_images=9):\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = next(dataiter) # Get a batch of images and labels\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(8, 8)) # Create a 3x3 grid for images\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        for i in range(n_images):\n",
    "            if i >= len(images): # Ensure we don't go out of bounds if batch size is smaller than n_images\n",
    "                break\n",
    "\n",
    "            ax = axes[i]\n",
    "            img = imshow(images[i]) # Use the helper function to properly display the image\n",
    "            ax.imshow(img)\n",
    "\n",
    "            # Get model output for the image\n",
    "            outputs = model(images[i].unsqueeze(0).to(device)) # Add batch dimension and move to device\n",
    "\n",
    "            # Get predicted class\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Get the class names\n",
    "            predicted_class_name = class_names[predicted.item()]\n",
    "            print(predicted_class_name)\n",
    "            \n",
    "            binary_label_idx = labels[0][i].item()\n",
    "            # true_class_name = class_names[labels[i]]\n",
    "\n",
    "            # Set the title with true and predicted labels\n",
    "            # 인덱스가 유효한 범위 내에 있는지 확인하고, 아니면 'Unknown'으로 처리합니다.\n",
    "            if 0 <= binary_label_idx < len(binary_labels_map):\n",
    "                label_text = binary_labels_map[binary_label_idx]\n",
    "            else:\n",
    "                label_text = f\"Unknown (Index: {binary_label_idx})\"\n",
    "\n",
    "            ax.set_title(f\"True: {binary_label_idx}, Label: {predicted_class_name}\")\n",
    "            # ax.set_title(f\"True: {true_class_name}\\nPred: {predicted_class_name}\", fontsize=10)\n",
    "            ax.axis('off') # Hide axes ticks\n",
    "\n",
    "    plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
    "    plt.show() # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = binary_labels_map\n",
    "display_predictions_binary_label(trainloader_2, model, class_names, device, n_images=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoAusGWS9Vb_"
   },
   "outputs": [],
   "source": [
    "for epoch in range(hyperparams[\"epochs\"]):\n",
    "    cost = 0.0\n",
    "\n",
    "    for images, classes in trainloader:\n",
    "        images = images.to(device)\n",
    "        classes = classes.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, classes)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(trainloader)\n",
    "    print(f\"Epoch : {epoch+1:4d}, Cost : {cost:.3f}\")\n",
    "    # print('Epoch %s: Train Accuracy: %.2f percent, Validation Accuracy: %.2f percent, Train Loss: %s, Validation Loss: %s'\n",
    "    #       % (epoch, train_acc, val_acc, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Jz2GvMZKTOk"
   },
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    accuracy = 0.0\n",
    "    for images, classes in testloader:\n",
    "        images = images.to(device)\n",
    "        classes = classes.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=-1)\n",
    "        outputs_classes = torch.argmax(probs, dim=-1)\n",
    "\n",
    "        accuracy += int(torch.eq(classes, outputs_classes).sum())\n",
    "\n",
    "    print(f\"acc@1 : {accuracy / (len(testloader) * hyperparams['batch_size']) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6CepWQBKTOl"
   },
   "outputs": [],
   "source": [
    "def display_predictions(loader, model, class_names, device, n_images=9):\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = next(dataiter) # Get a batch of images and labels\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(8, 8)) # Create a 3x3 grid for images\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        for i in range(n_images):\n",
    "            if i >= len(images): # Ensure we don't go out of bounds if batch size is smaller than n_images\n",
    "                break\n",
    "\n",
    "            ax = axes[i]\n",
    "            img = imshow(images[i]) # Use the helper function to properly display the image\n",
    "            ax.imshow(img)\n",
    "\n",
    "            # Get model output for the image\n",
    "            outputs = model(images[i].unsqueeze(0).to(device)) # Add batch dimension and move to device\n",
    "\n",
    "            # Get predicted class\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Get the class names\n",
    "            predicted_class_name = class_names[predicted.item()]\n",
    "            true_class_name = class_names[labels[i]]\n",
    "\n",
    "            # Set the title with true and predicted labels\n",
    "            ax.set_title(f\"True: {true_class_name}\\nPred: {predicted_class_name}\", fontsize=10)\n",
    "            ax.axis('off') # Hide axes ticks\n",
    "\n",
    "    plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
    "    plt.show() # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k4SOG57KTOm"
   },
   "outputs": [],
   "source": [
    "\n",
    "display_predictions(trainloader, model, class_names, device)\n",
    "display_predictions(testloader, model, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2JFSlQ0KTOn"
   },
   "outputs": [],
   "source": [
    "\n",
    "build_plainnet(is_50=False)\n",
    "\n",
    "build_plainnet(is_50=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
